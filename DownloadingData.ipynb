{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions for Loading Data\n",
    "\n",
    "Adapted from: https://github.com/pillowlab/psytrack_learning/blob/main/PsyTrack_Learning_Examples.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import re\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "from scipy.special import expit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import psytrack_learning as psy\n",
    "from psytrack_learning.getMAP import getMAP\n",
    "from psytrack_learning.helper.helperFunctions import update_hyper, hyper_to_list\n",
    "from psytrack_learning.helper.jacHessCheck import compHess, compHess_nolog\n",
    "from psytrack_learning.helper.invBlkTriDiag import getCredibleInterval\n",
    "from psytrack_learning.hyperparameter_optimization import evd_lossfun\n",
    "from psytrack_learning.learning_rules import RewardMax, PredictMax, REINFORCE, REINFORCE_base\n",
    "from psytrack_learning.simulate_learning import reward_max, predict_max, reinforce, reinforce_base \n",
    "from psytrack_learning.simulate_learning import simulate_learning\n",
    "\n",
    "\n",
    "# Set matplotlib defaults from making files editable and consistent in Illustrator\n",
    "colors = psy.COLORS\n",
    "zorder = psy.ZORDER\n",
    "plt.rcParams['figure.dpi'] = 140\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['savefig.facecolor'] = (1,1,1,0)\n",
    "plt.rcParams['savefig.bbox'] = \"tight\"\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['font.family'] = 'cmu serif'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['xtick.labelsize'] = 10\n",
    "plt.rcParams['ytick.labelsize'] = 10\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "\n",
    "# Set save path for preprocessed data and all figures\n",
    "spath = \"./Figures/\" # You can change this \n",
    "sim_colors = [\"#D81159\", \"#4357AD\", \"#EE8434\", \"#CC3399\", \"#409091\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and pre-process IBL mouse data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Download the [IBL dataset](https://doi.org/10.6084/m9.figshare.11636748.v7) (version 7, uploaded Feb 7, 2020).\n",
    "\n",
    "2) Update the `ibl_data_path` variable below to where the `ibl-behavioral-data-Dec2019` directory exists on your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibl_data_path = \"./Figures/\" # You can change this "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) We will also need to install the [ONE Light](https://github.com/int-brain-lab/ibllib/tree/master/oneibl) Python library (from the IBL) with `pip install ibllib`. This allows us to build a table of all the subject and session data contained within the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from oneibl.onelight import ONE\n",
    "import pandas as pd\n",
    "\n",
    "current_cwd = os.getcwd()\n",
    "os.chdir(ibl_data_path)\n",
    "\n",
    "# Search all sessions that have these dataset types.\n",
    "required_vars = ['_ibl_trials.choice', '_ibl_trials.contrastLeft',\n",
    "                 '_ibl_trials.contrastRight','_ibl_trials.feedbackType']\n",
    "one = ONE()\n",
    "eids = one.search(required_vars)\n",
    "\n",
    "mouseData = pd.DataFrame()\n",
    "for eid in eids:\n",
    "    lab, _, subject, date, session = eid.split(\"/\")    \n",
    "    sess_vars = {\n",
    "        \"eid\": eid,\n",
    "        \"lab\": lab,\n",
    "        \"subject\": subject,\n",
    "        \"date\": date,\n",
    "        \"session\": session,\n",
    "    }\n",
    "    mouseData = mouseData.append(sess_vars, sort=True, ignore_index=True)\n",
    "\n",
    "os.chdir(current_cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Next, we will use the table of session data to process the raw trial data below into a single CSV file, `ibl_processed.csv`, saved locally.\n",
    "\n",
    "There are several known anomalies in the raw data:\n",
    " - CSHL_002 codes left contrasts as negative right contrasts on 81 trials (these trials are corrected)\n",
    " - ZM_1084 has `feedbackType` of 0 for 3 trials (these trials are omitted)\n",
    " - DY_009, DY_010, DY_011 each have <5000 trials total (no adjustment)\n",
    " - ZM_1367, ZM_1369, ZM_1371, ZM_1372, and ZM_1743 are shown non-standard contrast values of 0.04 and 0.08 (no adjustment)\n",
    "\n",
    "_2 min_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vars = [\"contrastLeft\", \"contrastRight\", \"choice\", \"feedbackType\", \"probabilityLeft\"]\n",
    "df = pd.DataFrame()\n",
    "\n",
    "all_mice = []\n",
    "for j, s in enumerate(mouseData[\"subject\"].unique()):\n",
    "    print(\"\\rProcessing \" + str(j+1) + \" of \" + str(len(mouseData[\"subject\"].unique())), end=\"\")\n",
    "    mouse = mouseData[mouseData[\"subject\"]==s].sort_values(['date', 'session']).reset_index()\n",
    "    for i, row in mouse.iterrows():\n",
    "        myVars = {}\n",
    "        for v in all_vars:\n",
    "            filename = \"_ibl_trials.\" + v + \".npy\"\n",
    "            var_file = os.path.join(ibl_data_path, row.eid, \"alf\", filename)\n",
    "            myVars[v] = list(np.load(var_file).flatten())\n",
    "\n",
    "        num_trials = len(myVars[v])\n",
    "        myVars['lab'] = [row.lab]*num_trials\n",
    "        myVars['subject'] = [row.subject]*num_trials\n",
    "        myVars['date'] = [row.date]*num_trials\n",
    "        myVars['session'] = [row.session]*num_trials\n",
    "\n",
    "        all_mice += [pd.DataFrame(myVars, columns=myVars.keys())]\n",
    "        \n",
    "df = pd.concat(all_mice, ignore_index=True)\n",
    "\n",
    "df = df[df['choice'] != 0]        # dump mistrials\n",
    "df = df[df['feedbackType'] != 0]  # 3 anomalous trials from ZM_1084, omit\n",
    "df.loc[np.isnan(df['contrastLeft']), \"contrastLeft\"] = 0\n",
    "df.loc[np.isnan(df['contrastRight']), \"contrastRight\"] = 0\n",
    "df.loc[df[\"contrastRight\"] < 0, \"contrastLeft\"] = np.abs(df.loc[df[\"contrastRight\"] < 0, \"contrastRight\"])\n",
    "df.loc[df[\"contrastRight\"] < 0, \"contrastRight\"] = 0  # 81 anomalous trials in CSHL_002, correct\n",
    "df[\"answer\"] = df[\"feedbackType\"] * df[\"choice\"]      # new column to indicate correct answer\n",
    "df.loc[df[\"answer\"]==1, \"answer\"] = 0\n",
    "df.loc[df[\"answer\"]==-1, \"answer\"] = 1\n",
    "df.loc[df[\"feedbackType\"]==-1, \"feedbackType\"] = 0\n",
    "df.loc[df[\"choice\"]==1, \"choice\"] = 0\n",
    "df.loc[df[\"choice\"]==-1, \"choice\"] = 1\n",
    "df.to_csv(spath+\"ibl_processed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Next we do a few sanity checks on our data, to make sure everything processed correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"contrastLeft: \", np.unique(df['contrastLeft']))   # [0, 0.0625, 0.125, 0.25, 0.5, 1.0] and [0.04, 0.08]\n",
    "print(\"contrastRight: \", np.unique(df['contrastRight'])) # [0, 0.0625, 0.125, 0.25, 0.5, 1.0] and [0.04, 0.08]\n",
    "print(\"choice: \", np.unique(df['choice']))               # [0, 1]\n",
    "print(\"feedbackType: \", np.unique(df['feedbackType']))   # [0, 1]\n",
    "print(\"answer: \", np.unique(df['answer']))               # [0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Finally, we define a function `getMouse()` that extracts the data for a single mouse from our CSV file, and returns it in a PsyTrack compatible dictionary. We will use this function to access IBL mouse data in the figures below. Note the keyword argument and default value $p=5$ which controls the strength of the $\\tanh$ transformation on the contrast values. See Figure S3 and the STAR Methods for more details.\n",
    "\n",
    "**Note:** Once steps 1-6 have been run once, only step 6 will need to be run on subsequent uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_data_path = spath + \"ibl_processed.csv\"   # --- UPDATE if necessary ---\n",
    "MOUSE_DF = pd.read_csv(mouse_data_path)\n",
    "\n",
    "def getMouse(subject, p=5):\n",
    "    df = MOUSE_DF[MOUSE_DF['subject']==subject]   # Restrict data to the subject specified\n",
    "    \n",
    "    cL = np.tanh(p*df['contrastLeft'])/np.tanh(p)   # tanh transformation of left contrasts\n",
    "    cR = np.tanh(p*df['contrastRight'])/np.tanh(p)  # tanh transformation of right contrasts\n",
    "    cBoth = cR - cL\n",
    "    inputs = dict(cL = np.array(cL)[:, None], cR = np.array(cR)[:, None], cBoth = np.array(cBoth)[:, None])\n",
    "\n",
    "    dat = dict(\n",
    "        subject=subject,\n",
    "        lab=np.unique(df[\"lab\"])[0],\n",
    "        contrastLeft=np.array(df['contrastLeft']),\n",
    "        contrastRight=np.array(df['contrastRight']),\n",
    "        date=np.array(df['date']),\n",
    "        dayLength=np.array(df.groupby(['date','session']).size()),\n",
    "        correct=np.array(df['feedbackType']),\n",
    "        answer=np.array(df['answer']),\n",
    "        probL=np.array(df['probabilityLeft']),\n",
    "        inputs = inputs,\n",
    "        y = np.array(df['choice'])\n",
    "    )\n",
    "    \n",
    "    return dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
